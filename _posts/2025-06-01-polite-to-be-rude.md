--- 
layout: post 
title: It's rude to be polite in an AI world! 
---

[] Check if subtitle can be added

# Article Summary
- Years ago, it was considered important to be polite and use of overtly formal phrases in communications was appreciated
- Specialist like scribes would draft formal messages
- We live in a world where all of us carry a scribe in our pocket
- There is one slight problem, they are way too polite
- This is because they are trained to be encouraging to drive engagement
- In an ironical twist, we may need to employ methods to make our replies mildly rude so they feel authentic

# Introduction

If you happen to get your hands on old letters written by common folks to each other, you'll notice something curious - overly formal language and prose that seem to be straight out of a Charles Dicken's novel. Flowery vocabulary, elaborate pleasentries - this when they are written to close friends, family or even siblings (one would almost be mistaken to think that siblings didn't want to kill each other back in the days). This is, of course, in starc contrast to the "K, cya" you get from a generation which prefers heiroglyphics to communicate over meaningful phrases. To imagine that for centuries, the art of being civil in communication was honed by professionals and seasoned specialists - scribes, are now merely an app in your pocket. Soon, we may as well have an AI reply "K, cya" for us. Unfortunately, if you're not careful, your receipent may end up getting a nice and polite "Thanks for checking on me. I will see you soon" from an AI assistant, belying the fact that you didn't even take the effort to type few syllables and left it to a robot to do it on your behalf. How rude!

# Artifical Politeness

Humans have been interacting with bots for years now and in the process of training them, we have created an entity which is extremely deferential and servile. This is [already creating problems of a one kind](https://www.popsci.com/technology/openai-jerks/) but it is to be expected. After all, a model which blurts out truth bombs is hardly passing the systems of a human tester who, I imagine, would not take it kindly to a bot which calls them an unrequired overpaid regulatory moron. Also, despite [Sam Altman suugesting us](https://www.techinasia.com/news/being-polite-to-ai-thatll-cost-you-millions-altman-says) not to be polite to AI, it is going to take a lot more [to stop us from treating it like a human](https://www.diplomacy.edu/blog/politeness-in-2025-why-are-we-so-kind-to-ai/). Besides, it's a good thing that the chatbot is polite in its tone, what harm could come of that, you may ask.

# Representing the authentic you

In the recently concluded Google IO event, Sunadar Pichai demonstrated how, when a friend asked him for an advice, [Gemini parsed through his past emails and drafted a reply for him](https://blog.google/technology/ai/io-2025-keynote/#personalization). Reading that mail in the demo, I couldn't help but feel a sense of [Uncanny Valley](https://bluemonarchgroup.com/blog/the-uncanny-valley-of-communication-when-it-sounds-right-but-feels-wrong/). The mail, while trying to be as authentic as possible, still sounded like someone taking more effort to be helpful than a normal human being. Also, by relating this incident, he has made clear to the world that instead of taking the effort to reply to his friend, he would rather push a button and let it be some AI agent's problem. I can definitely imagine Felix leave the event with a sour taste after seeing that. Now imagine a new world where AI agents take care of the emails we don't bother to write, how amazing would it be to get a mail from a person who spent some time and effort to reach out to you.