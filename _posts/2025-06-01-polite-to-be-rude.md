--- 
layout: post 
title: It's rude to be polite in an AI world! 
subtitle: Why you need to work hard even with an AI
---
# Article Summary
- Years ago, it was considered important to be polite and use of overtly formal phrases in communications was appreciated
- Specialist like scribes would draft formal messages
- We live in a world where all of us carry a scribe in our pocket
- There is one slight problem, they are way too polite
- This is because they are trained to be encouraging to drive engagement
- In an ironical twist, we may need to employ methods to make our replies mildly rude so they feel authentic

# Introduction

If you happen to get your hands on old letters written by common folks to each other, you'll notice something curious - overly formal language and prose that seem to be straight out of a Charles Dicken's novel. Flowery vocabulary, elaborate pleasentries - this when they are written to close friends, family or even siblings (one would almost be mistaken to think that siblings didn't want to kill each other back in the days). This is, of course, in starc contrast to the "K, cya" you get from a generation which prefers heiroglyphics to communicate over meaningful phrases. To imagine that for centuries, the art of being civil in communication was honed by professionals and seasoned specialists - scribes, are now merely an app in your pocket. Soon, we may as well have an AI reply "K, cya" for us. Unfortunately, if you're not careful, your receipent may end up getting a nice and polite "Thanks for checking on me. I will see you soon" from an AI assistant, belying the fact that you didn't even take the effort to type few syllables and left it to a robot to do it on your behalf. How rude!

# Artifical Politeness

Humans have been interacting with bots for years now and in the process of training them, we have created an entity which is extremely deferential and servile. This is [already creating problems of a one kind](https://www.popsci.com/technology/openai-jerks/) but it is to be expected. After all, a model which blurts out truth bombs is hardly passing the systems of a human tester who, I imagine, would not take it kindly to a bot which calls them an unrequired overpaid regulatory moron. Also, despite [Sam Altman suugesting us](https://www.techinasia.com/news/being-polite-to-ai-thatll-cost-you-millions-altman-says) not to be polite to AI, it is going to take a lot more [to stop us from treating it like a human](https://www.diplomacy.edu/blog/politeness-in-2025-why-are-we-so-kind-to-ai/). Besides, it's a good thing that the chatbot is polite in its tone, what harm could come of that, you may ask.

# Representing the authentic you

In the recently concluded Google IO event, Sundar Pichai demonstrated how, when a friend asked him for an advice, [Gemini parsed through his past emails and drafted a reply for him](https://blog.google/technology/ai/io-2025-keynote/#personalization). Reading that mail in the demo, I couldn't help but feel a sense of [Uncanny Valley](https://bluemonarchgroup.com/blog/the-uncanny-valley-of-communication-when-it-sounds-right-but-feels-wrong/). The mail, while trying to be as authentic as possible, still sounded like someone taking way more effort to be helpful than a normal human being, let alone the CEO of Google. Also, by relating this incident, he has made clear to the world that instead of taking the effort to reply to his friend, he would rather push a button and let it be some AI agent's problem. I can definitely imagine Felix, who received the mail,  leave the event with a sour taste after seeing that. Now imagine a new world where AI agents take care of the emails nobody bothers to write on their own. How wonderful would it be to get a written communication that feels it was crafted by a human being?

Unfortunately, it takes lot of effort to write and replying to people on emails is an arduous task most of the time. Fortunately, with a bit of hard work we can definitely have an AI “me” which sends reply on our behalf and manages to be just irreverent enough to represent the authentic you. LLMs are by definition pattern generating device so their output is going to depend a lot on the training set provided to them. Theoretically, an LLM could parse through all your mail and create a voice which sound like yours and this is probably what Gemini did in our cited example. In theory, it sounds like a perfect solution. The problem is that we may be writing emails to a lot of people with varying familiarity and tone. There's a simple fix, we can ask AI to set the tone as friendly but when you do that, the model is likely to be overly polite. This may not be a problem now but if all your mails start sounding too similar, the receipent will start to realise that they are talking to a bot. A simple way to avoid it is to instruct the model to add a few lines which add a personal touch in each mail. _Also add a line asking about their recovery from the injury they had talked to me about_ a simple instruction added to the mail is just enough to show that you took care in drafting the reply and, in general, is a good practice to improve your network and maintain freindships. Even better, if you share enough camaraderie with the person, only if, then you can probably ask it to start the mail with a joke, _Draft a reply with a joke about how they plan at the last minute_ can probably work, even better if you supply a witty remark yourself and then ask AI to draft the rest of the mail. 
